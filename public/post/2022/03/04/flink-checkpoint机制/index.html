<!DOCTYPE html>
<html lang="cn-zh">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Flink Checkpoint机制 | 大道至简</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PGMJFXZJRT"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>

<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>

<link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/github.min.css"  rel="stylesheet">

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PGMJFXZJRT');
</script>
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Flink Checkpoint机制</span></h1>

<h2 class="date">2022/03/04</h2>
<p class="terms">
  
  
  
  
  Tags: <a href="/tags/flink">Flink</a> 
  
  
</p>
</div>



<main>
<p>摘要： 如果把运行中的 Flink 程序比做一条河流，Checkpoint 就是一个相机，定期地对河流进行拍照，记录河水的状态。本文以自顶向下的视角，从理论到实现，分析 Flink 中的 Checkpoint 机制；</p>
<hr>
<ul>
<li><a href="#%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80">理论基础</a>
<ul>
<li><a href="#asynchronous-barrier-snapshotting">asynchronous barrier snapshotting</a></li>
<li><a href="#%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4">算法步骤</a></li>
</ul>
</li>
<li><a href="#%E7%AE%97%E6%B3%95%E5%9C%A8-flink-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0">算法在 Flink 中的实现</a>
<ul>
<li><a href="#flink-checkpoint-%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B">Flink Checkpoint 整体流程</a></li>
<li><a href="#flink-checkpoint-barrier-alignment">Flink Checkpoint Barrier Alignment</a></li>
</ul>
</li>
<li><a href="#flink-checkpoint-%E4%BD%BF%E7%94%A8">Flink Checkpoint 使用</a>
<ul>
<li><a href="#flink-job-%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5">Flink Job 重启策略</a></li>
<li><a href="#flink-job-%E5%BC%80%E5%90%AF-checkpoint">Flink Job 开启 Checkpoint</a></li>
</ul>
</li>
</ul>
<h2 id="理论基础">理论基础</h2>
<h3 id="asynchronous-barrier-snapshotting">asynchronous barrier snapshotting</h3>
<p>Flink Checkpoint 机制是异步屏障快照（asynchronous barrier snapshotting, ABS）算法的一种实现，而 ABS 算法基于 <a href="https://archieyao.github.io/posts/2023-05-08-chandy-lamport%E7%AE%97%E6%B3%95/">Chandy-Lamport</a> 的变种，但数据模型是还是基于  Chandy-Lamport；</p>
<p>在 flink 中，作业算子被抽象为 DAG，节点为 operator，边是每一个 operator 的 stream（channel），与 Chandy-Lamport 的数据模型正好吻合；</p>
<p>ABS 算法把 Chandy-Lamport 中的 marker 消息换成了 barrier，作用是一致的，都是切分 snapshot；</p>
<p>ABS 算法 中 asynchronous 是异步的意思，当算子收齐 barrier 并触发快照之后，不会等待快照数据全部写入状态后端，而是一边后台写入，一边立刻继续处理数据流，并将 barrier 发送到下游，实现了最小化延迟。当然，引入异步性之后，所有有状态的算子都需要上报 ack，否则 JobManager 就无法确认一次 snapshot 是否完成。</p>
<h3 id="算法步骤">算法步骤</h3>
<ul>
<li>Source算子接收到JobManager产生的屏障，生成自己状态的快照（其中包含数据源对应的offset/position信息），并将屏障广播给下游所有数据流；</li>
<li>下游非 Source 的算子从它的某个输入数据流接收到屏障后，会阻塞这个输入流，继续接收其他输入流，直到所有输入流的屏障都到达。一旦算子收齐了所有屏障，它就会生成自己状态的快照，并继续将屏障广播给下游所有数据流；</li>
<li>Sink算子接收到屏障之后会向 JobManager 确认，所有Sink都确认收到屏障标记着这一周期checkpoint过程结束，快照成功。</li>
</ul>
<p>如果算子只有一个输入流的话，问题就比较简单，只需要在收到屏障之后立即做快照。但是如果有多个输入流，就必须要等待收到所有屏障才能做快照，以避免将检查点 n 与检查点 n + 1 的数据混淆。这个等待的过程就叫做对齐（alignment），见下图；</p>
<h2 id="算法在-flink-中的实现">算法在 Flink 中的实现</h2>
<p>在 Flink 的 stream 中，每一次的 Checkpoint 被 barrier 分割：</p>
<p><img src="/assets/img/stream_barriers.svg" alt="stream-barriers"></p>
<p>当算子接收到不止一个 steam 时，barrier 到达算子的顺序会不一致，此时，算子会停止处理新的数据，等到剩余的 barrier 到达算子后，才开始进行 Checkpoint，这就是 <code>Barrier Alignment</code> 。</p>
<p><img src="/assets/img/stream_aligning.svg" alt="stream-aligning"></p>
<h3 id="flink-checkpoint-整体流程">Flink Checkpoint 整体流程</h3>
<p><img src="/assets/img/checkpoint-flow.svg" alt="Checkpoint 流程"></p>
<p>Chekcpoint 是由 jobmanager 中的 CheckpointCoordinator 发起的，CheckpointCoordinator 是一个类，Flink 中具体描述如下：</p>
<pre><code class="language-java">// The checkpoint coordinator coordinates the distributed snapshots of operators and state.
// It triggers the checkpoint by sending the messages to the relevant tasks and 
// collects the checkpoint acknowledgements.
</code></pre>
<p>CheckpointCoordinator 会调度task 进行 checkpoint，并接收来自 tasks 的 ack；</p>
<p>用于保存 Checkpoint state 和 meta 的容器称为 state backend，Flink 中自带几种 state backend：</p>
<ul>
<li>MemoryStateBackend 内存型（默认）</li>
<li>FsStateBackend 文件系统，本地、hdfs、cos</li>
<li>RocksDBStateBackend 数据库RocksDB，存储在TaskManager的data目录下，也可以同步到远程</li>
</ul>
<h3 id="flink-checkpoint-barrier-alignment">Flink Checkpoint Barrier Alignment</h3>
<p>基于 Barrier Alignment，Checkpoint 产生两种模式：<code>EXACTLY_ONCE</code> <code>AT_LEAST_ONCE</code> ；</p>
<p>当 Barrier Alignment 时，先到来的数据进行 buffer，就是 <code>EXACTLY_ONCE</code>，当先到来的数据先进行处理时，就是 <code>AT_LEAST_ONCE</code> 。</p>
<p>从Flink 1.11开始，Checkpoint 可以是非对齐的。 Unaligned checkpoints 包含 In-flight 数据(例如，存储在缓冲区中的数据)作为 Checkpoint State的一部分，允许 Checkpoint Barrier 跨越这些缓冲区。因此，Checkpoint 时长变得与当前吞吐量无关，因为 Checkpoint Barrier 实际上已经不再嵌入到数据流当中。 使用  Unaligned checkpoints 也会带来新的代价，State 中会保存数据，这样会增加 State 的负担；</p>
<p>如果到算子背压是由于 Checkpoint 周期过长（Barrier Alignment）时，此时建议使用  Unaligned checkpoint；</p>
<pre><code class="language-java">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
// 启用非对齐 Checkpoint
env.getCheckpointConfig().enableUnalignedCheckpoints();
</code></pre>
<h2 id="flink-checkpoint-使用">Flink Checkpoint 使用</h2>
<h3 id="flink-job-重启策略">Flink Job 重启策略</h3>
<p>在作业运行时，经常会由于各种不确定因素导致作业停止，网络，磁盘，外部依赖等等，Flink 内部提供多种作业重启的策略来减少运维成本，Flink 程序设置重启策略后，当作业停止时，Flink 可以重新拉起作业，常用的重启策略如下：</p>
<pre><code class="language-java">StreamExecutionEnvironment executionEnvironment =
        StreamExecutionEnvironment.getExecutionEnvironment();
// 默认重启策略，没有重启策略
executionEnvironment.setRestartStrategy(RestartStrategies.noRestart());
// 采用集群的重启策略，如果没有定义其他重启策略，默认选择固定延时重启策略。
executionEnvironment.setRestartStrategy(RestartStrategies.fallBackRestart());
// 采用集群的重启策略，如果没有定义其他重启策略，默认选择固定延时重启策略。
executionEnvironment.setRestartStrategy(RestartStrategies.fallBackRestart());
// 如果20 S 内，有1次错误，则终止作业，不满足则会重启作业，重启时间间隔为 5 S
executionEnvironment.setRestartStrategy(
        RestartStrategies.failureRateRestart(1, Time.seconds(20), Time.seconds(5)));
</code></pre>
<p>source 定义了一个 Tuple3 的数据源，index 一直自增，在 map 过程中，遇到 100 时抛出一个异常； 作业运行的结果是，当 index=100 时，作业失败，然后重启，重新开始运行：</p>
<pre><code class="language-java">
public class MapFunc {
    public static MapFunction&lt;Tuple3&lt;String, Integer, Long&gt;, Tuple2&lt;String, Integer&gt;&gt; getMapFunc(
            Logger logger) {
        return new MapFunction&lt;Tuple3&lt;String, Integer, Long&gt;, Tuple2&lt;String, Integer&gt;&gt;() {
            @Override
            public Tuple2&lt;String, Integer&gt; map(Tuple3&lt;String, Integer, Long&gt; event)
                    throws Exception {
                if (event.f1 % 100 == 0) {
                    logger.error(&quot;event.f1 more than 100. value : &quot; + event.f1);
                    throw new RuntimeException(&quot;event.f1 more than 100.&quot;);
                }
                return new Tuple2&lt;&gt;(event.f0, event.f1);
            }
        };
    }
}

// 运行作业
public class FixedDelayRestartJob {

    public static void main(String[] args) throws Exception {
        Logger logger = LoggerFactory.getLogger(FixedDelayRestartJob.class);
        StreamExecutionEnvironment executionEnvironment =
                StreamExecutionEnvironment.getExecutionEnvironment();
        executionEnvironment.setParallelism(1);
        // 重启尝试次数 2，每次重启间隔 5 S
        executionEnvironment.setRestartStrategy(
                RestartStrategies.fixedDelayRestart(2, Time.seconds(5)));
        // source
        DataStreamSource&lt;Tuple3&lt;String, Integer, Long&gt;&gt; source =
                executionEnvironment.addSource(SourceFunc.getSourceFunc(logger));
        // map operator
        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; operator =
                source.map(MapFunc.getMapFunc(logger));
        // sink
        operator.print();
        executionEnvironment.execute(&quot;not-restart&quot;);
    }
}
</code></pre>
<h3 id="flink-job-开启-checkpoint">Flink Job 开启 Checkpoint</h3>
<p>在给 Flink 作业设置重启策略后，作业失败时会重新运行，此时，作业是从最开始的位置开始运行，每次重新启动后，上述示例中的 sum 都会从 0 开始；</p>
<p>在真实场景下，通常不需要作业又重新把历史数据都计算一次，因为可能会造成数据重复，Flink 中因此引入了 Checkpoint 机制，作业可以利用 Checkpoint 保存 sum 的值，在失败的地方重新启动，此时 sum 的值会从 Checkpoint 中读取，并持续累加。</p>
<pre><code class="language-java">// 重启尝试次数 2，每次重启间隔 5 S
executionEnvironment.setRestartStrategy(RestartStrategies.fixedDelayRestart(2, Time.seconds(5)));
// 每10ms进行一次 Checkpoint
executionEnvironment.enableCheckpointing(10);
</code></pre>
<p>完整代码地址： <a href="https://github.com/ArchieYao/flink-learning/tree/main/hello-world">https://github.com/ArchieYao/flink-learning/tree/main/hello-world</a></p>
<hr>
<p>参考：</p>
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/ops/state/checkpointing_under_backpressure/">https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/ops/state/checkpointing_under_backpressure/</a></p>

</main>

  <footer>
  
  <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "qiref" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

  
  <hr/>
  © powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/yihui/hugo-xmin">Xmin</a>  2017 &ndash; 2025 | <a href="https://github.com/qiref">Github</a>
  
  </footer>
  </body>
</html>


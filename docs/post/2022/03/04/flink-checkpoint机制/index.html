<!DOCTYPE html>
<html lang="cn-zh">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Flink Checkpoint机制 | 大道至简</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PGMJFXZJRT"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>

<script>
hljs.configure({languages: []});
hljs.highlightAll();
</script>

<link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/github.min.css"  rel="stylesheet">

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PGMJFXZJRT');
</script>

<link rel="stylesheet" href="/css/custom.css">
<link rel="stylesheet" href="/css/heatmap.css">
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/post/">Posts</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/note/">Note</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
      <li class="search-container">
        <input type="text" id="search-input" placeholder="⌘ K" autocomplete="off">
        <div id="search-results"></div>
      </li>
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Flink Checkpoint机制</span></h1>

<h2 class="date">2022/03/04</h2>
<p class="terms">
  
  
  
  
  Tags: <a href="/tags/flink">Flink</a> 
  
  
</p>
</div>



<main>
<p>摘要： 如果把运行中的 Flink 程序比做一条河流，Checkpoint 就是一个相机，定期地对河流进行拍照，记录河水的状态。本文以自顶向下的视角，从理论到实现，分析 Flink 中的 Checkpoint 机制；</p>
<hr>
<ul>
<li><a href="#%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80">理论基础</a>
<ul>
<li><a href="#asynchronous-barrier-snapshotting">asynchronous barrier snapshotting</a></li>
<li><a href="#%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4">算法步骤</a></li>
</ul>
</li>
<li><a href="#%E7%AE%97%E6%B3%95%E5%9C%A8-flink-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0">算法在 Flink 中的实现</a>
<ul>
<li><a href="#flink-checkpoint-%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B">Flink Checkpoint 整体流程</a></li>
<li><a href="#flink-checkpoint-barrier-alignment">Flink Checkpoint Barrier Alignment</a></li>
</ul>
</li>
<li><a href="#flink-checkpoint-%E4%BD%BF%E7%94%A8">Flink Checkpoint 使用</a>
<ul>
<li><a href="#flink-job-%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5">Flink Job 重启策略</a></li>
<li><a href="#flink-job-%E5%BC%80%E5%90%AF-checkpoint">Flink Job 开启 Checkpoint</a></li>
</ul>
</li>
</ul>
<h2 id="理论基础">理论基础</h2>
<h3 id="asynchronous-barrier-snapshotting">asynchronous barrier snapshotting</h3>
<p>Flink Checkpoint 机制是异步屏障快照（asynchronous barrier snapshotting, ABS）算法的一种实现，而 ABS 算法基于 <a href="https://archieyao.github.io/posts/2023-05-08-chandy-lamport%E7%AE%97%E6%B3%95/">Chandy-Lamport</a> 的变种，但数据模型是还是基于  Chandy-Lamport；</p>
<p>在 flink 中，作业算子被抽象为 DAG，节点为 operator，边是每一个 operator 的 stream（channel），与 Chandy-Lamport 的数据模型正好吻合；</p>
<p>ABS 算法把 Chandy-Lamport 中的 marker 消息换成了 barrier，作用是一致的，都是切分 snapshot；</p>
<p>ABS 算法 中 asynchronous 是异步的意思，当算子收齐 barrier 并触发快照之后，不会等待快照数据全部写入状态后端，而是一边后台写入，一边立刻继续处理数据流，并将 barrier 发送到下游，实现了最小化延迟。当然，引入异步性之后，所有有状态的算子都需要上报 ack，否则 JobManager 就无法确认一次 snapshot 是否完成。</p>
<h3 id="算法步骤">算法步骤</h3>
<ul>
<li>Source算子接收到JobManager产生的屏障，生成自己状态的快照（其中包含数据源对应的offset/position信息），并将屏障广播给下游所有数据流；</li>
<li>下游非 Source 的算子从它的某个输入数据流接收到屏障后，会阻塞这个输入流，继续接收其他输入流，直到所有输入流的屏障都到达。一旦算子收齐了所有屏障，它就会生成自己状态的快照，并继续将屏障广播给下游所有数据流；</li>
<li>Sink算子接收到屏障之后会向 JobManager 确认，所有Sink都确认收到屏障标记着这一周期checkpoint过程结束，快照成功。</li>
</ul>
<p>如果算子只有一个输入流的话，问题就比较简单，只需要在收到屏障之后立即做快照。但是如果有多个输入流，就必须要等待收到所有屏障才能做快照，以避免将检查点 n 与检查点 n + 1 的数据混淆。这个等待的过程就叫做对齐（alignment），见下图；</p>
<h2 id="算法在-flink-中的实现">算法在 Flink 中的实现</h2>
<p>在 Flink 的 stream 中，每一次的 Checkpoint 被 barrier 分割：</p>
<p><img src="/assets/img/stream_barriers.svg" alt="stream-barriers"></p>
<p>当算子接收到不止一个 steam 时，barrier 到达算子的顺序会不一致，此时，算子会停止处理新的数据，等到剩余的 barrier 到达算子后，才开始进行 Checkpoint，这就是 <code>Barrier Alignment</code> 。</p>
<p><img src="/assets/img/stream_aligning.svg" alt="stream-aligning"></p>
<h3 id="flink-checkpoint-整体流程">Flink Checkpoint 整体流程</h3>
<p><img src="/assets/img/checkpoint-flow.svg" alt="Checkpoint 流程"></p>
<p>Chekcpoint 是由 jobmanager 中的 CheckpointCoordinator 发起的，CheckpointCoordinator 是一个类，Flink 中具体描述如下：</p>
<pre><code class="language-java">// The checkpoint coordinator coordinates the distributed snapshots of operators and state.
// It triggers the checkpoint by sending the messages to the relevant tasks and 
// collects the checkpoint acknowledgements.
</code></pre>
<p>CheckpointCoordinator 会调度task 进行 checkpoint，并接收来自 tasks 的 ack；</p>
<p>用于保存 Checkpoint state 和 meta 的容器称为 state backend，Flink 中自带几种 state backend：</p>
<ul>
<li>MemoryStateBackend 内存型（默认）</li>
<li>FsStateBackend 文件系统，本地、hdfs、cos</li>
<li>RocksDBStateBackend 数据库RocksDB，存储在TaskManager的data目录下，也可以同步到远程</li>
</ul>
<h3 id="flink-checkpoint-barrier-alignment">Flink Checkpoint Barrier Alignment</h3>
<p>基于 Barrier Alignment，Checkpoint 产生两种模式：<code>EXACTLY_ONCE</code> <code>AT_LEAST_ONCE</code> ；</p>
<p>当 Barrier Alignment 时，先到来的数据进行 buffer，就是 <code>EXACTLY_ONCE</code>，当先到来的数据先进行处理时，就是 <code>AT_LEAST_ONCE</code> 。</p>
<p>从Flink 1.11开始，Checkpoint 可以是非对齐的。 Unaligned checkpoints 包含 In-flight 数据(例如，存储在缓冲区中的数据)作为 Checkpoint State的一部分，允许 Checkpoint Barrier 跨越这些缓冲区。因此，Checkpoint 时长变得与当前吞吐量无关，因为 Checkpoint Barrier 实际上已经不再嵌入到数据流当中。 使用  Unaligned checkpoints 也会带来新的代价，State 中会保存数据，这样会增加 State 的负担；</p>
<p>如果到算子背压是由于 Checkpoint 周期过长（Barrier Alignment）时，此时建议使用  Unaligned checkpoint；</p>
<pre><code class="language-java">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
// 启用非对齐 Checkpoint
env.getCheckpointConfig().enableUnalignedCheckpoints();
</code></pre>
<h2 id="flink-checkpoint-使用">Flink Checkpoint 使用</h2>
<h3 id="flink-job-重启策略">Flink Job 重启策略</h3>
<p>在作业运行时，经常会由于各种不确定因素导致作业停止，网络，磁盘，外部依赖等等，Flink 内部提供多种作业重启的策略来减少运维成本，Flink 程序设置重启策略后，当作业停止时，Flink 可以重新拉起作业，常用的重启策略如下：</p>
<pre><code class="language-java">StreamExecutionEnvironment executionEnvironment =
        StreamExecutionEnvironment.getExecutionEnvironment();
// 默认重启策略，没有重启策略
executionEnvironment.setRestartStrategy(RestartStrategies.noRestart());
// 采用集群的重启策略，如果没有定义其他重启策略，默认选择固定延时重启策略。
executionEnvironment.setRestartStrategy(RestartStrategies.fallBackRestart());
// 采用集群的重启策略，如果没有定义其他重启策略，默认选择固定延时重启策略。
executionEnvironment.setRestartStrategy(RestartStrategies.fallBackRestart());
// 如果20 S 内，有1次错误，则终止作业，不满足则会重启作业，重启时间间隔为 5 S
executionEnvironment.setRestartStrategy(
        RestartStrategies.failureRateRestart(1, Time.seconds(20), Time.seconds(5)));
</code></pre>
<p>source 定义了一个 Tuple3 的数据源，index 一直自增，在 map 过程中，遇到 100 时抛出一个异常； 作业运行的结果是，当 index=100 时，作业失败，然后重启，重新开始运行：</p>
<pre><code class="language-java">
public class MapFunc {
    public static MapFunction&lt;Tuple3&lt;String, Integer, Long&gt;, Tuple2&lt;String, Integer&gt;&gt; getMapFunc(
            Logger logger) {
        return new MapFunction&lt;Tuple3&lt;String, Integer, Long&gt;, Tuple2&lt;String, Integer&gt;&gt;() {
            @Override
            public Tuple2&lt;String, Integer&gt; map(Tuple3&lt;String, Integer, Long&gt; event)
                    throws Exception {
                if (event.f1 % 100 == 0) {
                    logger.error(&quot;event.f1 more than 100. value : &quot; + event.f1);
                    throw new RuntimeException(&quot;event.f1 more than 100.&quot;);
                }
                return new Tuple2&lt;&gt;(event.f0, event.f1);
            }
        };
    }
}

// 运行作业
public class FixedDelayRestartJob {

    public static void main(String[] args) throws Exception {
        Logger logger = LoggerFactory.getLogger(FixedDelayRestartJob.class);
        StreamExecutionEnvironment executionEnvironment =
                StreamExecutionEnvironment.getExecutionEnvironment();
        executionEnvironment.setParallelism(1);
        // 重启尝试次数 2，每次重启间隔 5 S
        executionEnvironment.setRestartStrategy(
                RestartStrategies.fixedDelayRestart(2, Time.seconds(5)));
        // source
        DataStreamSource&lt;Tuple3&lt;String, Integer, Long&gt;&gt; source =
                executionEnvironment.addSource(SourceFunc.getSourceFunc(logger));
        // map operator
        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; operator =
                source.map(MapFunc.getMapFunc(logger));
        // sink
        operator.print();
        executionEnvironment.execute(&quot;not-restart&quot;);
    }
}
</code></pre>
<h3 id="flink-job-开启-checkpoint">Flink Job 开启 Checkpoint</h3>
<p>在给 Flink 作业设置重启策略后，作业失败时会重新运行，此时，作业是从最开始的位置开始运行，每次重新启动后，上述示例中的 sum 都会从 0 开始；</p>
<p>在真实场景下，通常不需要作业又重新把历史数据都计算一次，因为可能会造成数据重复，Flink 中因此引入了 Checkpoint 机制，作业可以利用 Checkpoint 保存 sum 的值，在失败的地方重新启动，此时 sum 的值会从 Checkpoint 中读取，并持续累加。</p>
<pre><code class="language-java">// 重启尝试次数 2，每次重启间隔 5 S
executionEnvironment.setRestartStrategy(RestartStrategies.fixedDelayRestart(2, Time.seconds(5)));
// 每10ms进行一次 Checkpoint
executionEnvironment.enableCheckpointing(10);
</code></pre>
<p>完整代码地址： <a href="https://github.com/ArchieYao/flink-learning/tree/main/hello-world">https://github.com/ArchieYao/flink-learning/tree/main/hello-world</a></p>
<hr>
<p>参考：</p>
<p><a href="https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/ops/state/checkpointing_under_backpressure/">https://nightlies.apache.org/flink/flink-docs-release-1.16/zh/docs/ops/state/checkpointing_under_backpressure/</a></p>

</main>

  <footer>
  
<script src="https://utteranc.es/client.js"
        repo="qiref/qiref.github.io"
        issue-term="pathname"
        label="Comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>


<script>
(function() {
  const searchInput = document.getElementById('search-input');
  const searchResults = document.getElementById('search-results');
  if (!searchInput || !searchResults) return;
  
  let searchIndex = null;
  let activeIndex = -1;
  let isResultsVisible = false;

  
  async function loadSearchIndex() {
    if (searchIndex) return searchIndex;
    try {
      const response = await fetch('/index.json');
      const data = await response.json();
      searchIndex = data.pages || [];
      return searchIndex;
    } catch (e) {
      console.error('Failed to load search index:', e);
      return [];
    }
  }

  
  function search(query) {
    if (!searchIndex || !query.trim()) return [];
    const q = query.toLowerCase();
    return searchIndex.filter(page => {
      const title = (page.title || '').toLowerCase();
      const content = (page.content || '').toLowerCase();
      return title.includes(q) || content.includes(q);
    }).slice(0, 10);
  }

  
  function highlight(text, query) {
    if (!query) return text;
    const regex = new RegExp(`(${query.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')})`, 'gi');
    return text.replace(regex, '<mark>$1</mark>');
  }

  
  function showResults() {
    searchResults.style.display = 'block';
    isResultsVisible = true;
  }

  
  function hideResults() {
    searchResults.style.display = 'none';
    isResultsVisible = false;
    activeIndex = -1;
  }

  
  function updateActiveItem() {
    const items = searchResults.querySelectorAll('.search-result-item');
    items.forEach((item, index) => {
      if (index === activeIndex) {
        item.classList.add('active');
      } else {
        item.classList.remove('active');
      }
    });
  }

  
  function renderResults(results, query) {
    activeIndex = -1;
    if (!results.length) {
      hideResults();
      return;
    }
    const html = results.map(page => {
      const title = highlight(page.title || 'Untitled', query);
      let summary = page.summary || page.content || '';
      summary = summary.substring(0, 100) + (summary.length > 100 ? '...' : '');
      return `<a class="search-result-item" href="${page.url}">
        <div class="search-result-title">${title}</div>
        <div class="search-result-summary">${summary}</div>
      </a>`;
    }).join('');
    searchResults.innerHTML = html;
    showResults();
  }

  
  let debounceTimer;
  function debounce(fn, delay) {
    return function(...args) {
      clearTimeout(debounceTimer);
      debounceTimer = setTimeout(() => fn.apply(this, args), delay);
    };
  }

  
  searchInput.addEventListener('input', debounce(async function() {
    const query = this.value.trim();
    if (!query) {
      hideResults();
      return;
    }
    await loadSearchIndex();
    const results = search(query);
    renderResults(results, query);
  }, 200));

  
  searchInput.addEventListener('keydown', function(e) {
    if (!isResultsVisible) return;
    
    const items = searchResults.querySelectorAll('.search-result-item');
    const itemCount = items.length;
    if (itemCount === 0) return;

    switch (e.key) {
      case 'ArrowDown':
        e.preventDefault();
        e.stopPropagation();
        activeIndex = (activeIndex + 1) % itemCount;
        updateActiveItem();
        break;
      case 'ArrowUp':
        e.preventDefault();
        e.stopPropagation();
        activeIndex = activeIndex <= 0 ? itemCount - 1 : activeIndex - 1;
        updateActiveItem();
        break;
      case 'Enter':
        if (activeIndex >= 0 && items[activeIndex]) {
          e.preventDefault();
          window.location.href = items[activeIndex].href;
        }
        break;
      case 'Escape':
        e.preventDefault();
        hideResults();
        break;
    }
  });

  
  searchInput.addEventListener('focus', async function() {
    const query = this.value.trim();
    if (query) {
      await loadSearchIndex();
      const results = search(query);
      renderResults(results, query);
    }
  });

  
  document.addEventListener('click', function(e) {
    if (!searchInput.contains(e.target) && !searchResults.contains(e.target)) {
      hideResults();
    }
  });

  
  document.addEventListener('keydown', function(e) {
    if ((e.metaKey || e.ctrlKey) && e.key === 'k') {
      e.preventDefault();
      searchInput.focus();
      searchInput.select();
    }
  });
})();
</script>
  
  <hr/>
  © powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/yihui/hugo-xmin">Xmin</a>  2017 &ndash; 2025 | <a href="https://github.com/qiref">Github</a>
  
  </footer>
  </body>
</html>


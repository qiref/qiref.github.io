<!DOCTYPE html>
<html lang="cn-zh">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Flink源码学习指南 | 大道至简</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PGMJFXZJRT"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>

<script>
hljs.configure({languages: []});
hljs.highlightAll();
</script>

<link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/github.min.css"  rel="stylesheet">

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PGMJFXZJRT');
</script>

<link rel="stylesheet" href="/css/custom.css">
<link rel="stylesheet" href="/css/heatmap.css">
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/post/">Posts</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/note/">Note</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
      <li class="search-container">
        <input type="text" id="search-input" placeholder="⌘ K" autocomplete="off">
        <div id="search-results"></div>
      </li>
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Flink源码学习指南</span></h1>

<h2 class="date">2025/12/04</h2>
<p class="terms">
  
  
  
  
  Tags: <a href="/tags/flink">Flink</a> 
  
  
</p>
</div>


<nav id="TableOfContents">
  <ul>
    <li><a href="#flink-整体架构概览">Flink 整体架构概览</a>
      <ul>
        <li><a href="#三层架构模型">三层架构模型</a></li>
        <li><a href="#作业执行流程">作业执行流程</a></li>
      </ul>
    </li>
    <li><a href="#源码深入分析">源码深入分析</a>
      <ul>
        <li><a href="#第一阶段streamgraph-生成">第一阶段：StreamGraph 生成</a></li>
        <li><a href="#第二阶段jobgraph-生成">第二阶段：JobGraph 生成</a></li>
        <li><a href="#第三阶段作业提交与调度">第三阶段：作业提交与调度</a></li>
        <li><a href="#第四阶段taskmanager-执行">第四阶段：TaskManager 执行</a></li>
        <li><a href="#第五阶段checkpoint-机制">第五阶段：Checkpoint 机制</a></li>
      </ul>
    </li>
    <li><a href="#关键类速查表">关键类速查表</a></li>
    <li><a href="#调试技巧">调试技巧</a>
      <ul>
        <li><a href="#关键断点位置">关键断点位置</a></li>
        <li><a href="#日志配置">日志配置</a></li>
        <li><a href="#web-ui-观察点">Web UI 观察点</a></li>
      </ul>
    </li>
  </ul>
</nav>


<main>
<p>从 Flink 的整体架构开始，建立全局视野，再深入源码细节。</p>
<h2 id="flink-整体架构概览">Flink 整体架构概览</h2>
<h3 id="三层架构模型">三层架构模型</h3>
<p>Flink 采用经典的主从架构，分为三层：</p>
<p><strong>Client Layer（客户端层）</strong></p>
<ul>
<li>Client：用户程序入口</li>
<li>JobGraph Generation：将用户代码转换为 JobGraph</li>
<li>Job Submission：提交作业到集群</li>
</ul>
<p><strong>Master Layer（主节点层）</strong></p>
<ul>
<li>JobManager：集群主节点，包含以下组件：
<ul>
<li>Dispatcher：接收作业提交，管理作业生命周期</li>
<li>ResourceManager：管理 TaskManager 资源，分配 slot</li>
<li>JobMaster：单个作业的协调者，负责调度和 checkpoint</li>
<li>Checkpoint Coordinator：协调 checkpoint 流程</li>
<li>Scheduler：任务调度器</li>
</ul>
</li>
</ul>
<p><strong>Worker Layer（工作节点层）</strong></p>
<ul>
<li>TaskManager：工作节点，包含以下组件：
<ul>
<li>Task Slot：执行具体任务的容器</li>
<li>Network Stack：处理数据交换</li>
<li>State Backend：管理算子状态</li>
</ul>
</li>
</ul>
<h3 id="作业执行流程">作业执行流程</h3>
<p>以一个简单的 FileSinkDemo 为例：</p>
<pre><code class="language-java">StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(conf);
DataStream&lt;String&gt; source = env.fromData(&quot;hello&quot;, &quot;world&quot;, &quot;flink&quot;);
source.sinkTo(fileSink);
env.execute();
</code></pre>
<p>完整执行流程：</p>
<pre><code>用户代码 ---&gt; StreamGraph ---&gt; JobGraph ---&gt; ExecutionGraph ---&gt; 物理执行
   |              |              |               |                  |
 Client        Client        Client         JobMaster          TaskManager
</code></pre>
<h2 id="源码深入分析">源码深入分析</h2>
<h3 id="第一阶段streamgraph-生成">第一阶段：StreamGraph 生成</h3>
<h4 id="入口streamexecutionenvironment">入口：StreamExecutionEnvironment</h4>
<p>当调用 <code>env.fromData()</code> 时，实际执行的是：</p>
<pre><code class="language-java">// StreamExecutionEnvironment.java
public &lt;OUT&gt; DataStreamSource&lt;OUT&gt; fromData(OUT... data) {
    return fromData(Arrays.asList(data));
}

public &lt;OUT&gt; DataStreamSource&lt;OUT&gt; fromData(Collection&lt;OUT&gt; data) {
    // 1. 推断数据类型
    TypeInformation&lt;OUT&gt; typeInfo = TypeExtractor.getForObject(data.iterator().next());
    // 2. 创建 Source Function
    return fromCollection(data, typeInfo);
}
</code></pre>
<p>关键方法 <code>addSource()</code>：</p>
<pre><code class="language-java">// StreamExecutionEnvironment.java
public &lt;OUT&gt; DataStreamSource&lt;OUT&gt; addSource(SourceFunction&lt;OUT&gt; function) {
    // 核心：向 transformations 列表添加一个 LegacySourceTransformation
    TypeInformation&lt;OUT&gt; outTypeInfo = extractTypeInfo(function);
    StreamSource&lt;OUT, ?&gt; sourceOperator = new StreamSource&lt;&gt;(function);
    return new DataStreamSource&lt;&gt;(this, outTypeInfo, sourceOperator, isParallel, sourceName);
}
</code></pre>
<p><strong>关键数据结构</strong>：<code>transformations</code> 是一个 <code>List&lt;Transformation&lt;?&gt;&gt;</code> ，存储了所有的算子转换。</p>
<h4 id="datastream-的链式调用">DataStream 的链式调用</h4>
<p>每次调用 <code>map()</code>, <code>filter()</code>, <code>sinkTo()</code> 等方法，都会创建新的 <code>Transformation</code> 并加入列表：</p>
<pre><code class="language-java">// DataStream.java
public &lt;R&gt; SingleOutputStreamOperator&lt;R&gt; map(MapFunction&lt;T, R&gt; mapper) {
    TypeInformation&lt;R&gt; outType = TypeExtractor.getMapReturnTypes(...);
    // 创建 OneInputTransformation
    return transform(&quot;Map&quot;, outType, new StreamMap&lt;&gt;(clean(mapper)));
}

protected &lt;R&gt; SingleOutputStreamOperator&lt;R&gt; transform(String operatorName, 
        TypeInformation&lt;R&gt; outTypeInfo, OneInputStreamOperator&lt;T, R&gt; operator) {
    // 1. 创建 Transformation
    OneInputTransformation&lt;T, R&gt; transformation = new OneInputTransformation&lt;&gt;(
            this.transformation,  // 上游 transformation
            operatorName,
            operator,
            outTypeInfo,
            environment.getParallelism());
    // 2. 加入 transformations 列表
    getExecutionEnvironment().addOperator(transformation);
    return new SingleOutputStreamOperator&lt;&gt;(environment, transformation);
}
</code></pre>
<p><strong>Transformation 继承体系</strong>：</p>
<pre><code>Transformation&lt;T&gt;
├── SourceTransformation          # Source 算子
├── SinkTransformation            # Sink 算子
├── OneInputTransformation        # 单输入算子 (map, filter)
├── TwoInputTransformation        # 双输入算子 (join, connect)
├── PartitionTransformation       # 分区算子 (keyBy, rebalance)
└── UnionTransformation           # union 算子
</code></pre>
<h4 id="execute-触发-streamgraph-生成">execute() 触发 StreamGraph 生成</h4>
<pre><code class="language-java">// StreamExecutionEnvironment.java
public JobExecutionResult execute(String jobName) throws Exception {
    // 1. 生成 StreamGraph
    StreamGraph streamGraph = getStreamGraph();
    // 2. 提交执行
    return execute(streamGraph);
}

public StreamGraph getStreamGraph() {
    // 核心：StreamGraphGenerator 遍历 transformations 生成 StreamGraph
    return getStreamGraphGenerator(transformations).generate();
}
</code></pre>
<p><strong>StreamGraphGenerator 核心逻辑</strong>：</p>
<pre><code class="language-java">// StreamGraphGenerator.java
public StreamGraph generate() {
    streamGraph = new StreamGraph(executionConfig, checkpointConfig, ...);
    // 遍历所有 transformation，转换为 StreamNode
    for (Transformation&lt;?&gt; transformation : transformations) {
        transform(transformation);
    }
    return streamGraph;
}

private Collection&lt;Integer&gt; transform(Transformation&lt;?&gt; transform) {
    // 根据不同类型的 Transformation 调用不同的转换方法
    if (transform instanceof OneInputTransformation) {
        return transformOneInputTransform((OneInputTransformation&lt;?, ?&gt;) transform);
    } else if (transform instanceof SourceTransformation) {
        return transformSource((SourceTransformation&lt;?&gt;) transform);
    }
    // ... 其他类型
}
</code></pre>
<p><strong>StreamGraph 核心数据结构</strong>：</p>
<pre><code class="language-java">// StreamGraph.java
public class StreamGraph {
    // 节点：算子
    private Map&lt;Integer, StreamNode&gt; streamNodes = new HashMap&lt;&gt;();
    // 边：数据流向
    private Set&lt;StreamEdge&gt; edges = new HashSet&lt;&gt;();
    // Source 节点 ID 列表
    private Set&lt;Integer&gt; sources = new HashSet&lt;&gt;();
    // Sink 节点 ID 列表
    private Set&lt;Integer&gt; sinks = new HashSet&lt;&gt;();
}

// StreamNode.java
public class StreamNode {
    private final int id;                           // 节点 ID
    private String operatorName;                    // 算子名称
    private StreamOperatorFactory&lt;?&gt; operatorFactory;  // 算子工厂
    private List&lt;StreamEdge&gt; inEdges;               // 输入边
    private List&lt;StreamEdge&gt; outEdges;              // 输出边
    private int parallelism;                        // 并行度
}
</code></pre>
<h3 id="第二阶段jobgraph-生成">第二阶段：JobGraph 生成</h3>
<p>StreamGraph 生成后，需要转换为 JobGraph 用于提交：</p>
<pre><code class="language-java">// StreamGraph.java
public JobGraph getJobGraph() {
    return StreamingJobGraphGenerator.createJobGraph(this);
}
</code></pre>
<p><strong>核心优化：算子链（Operator Chaining）</strong></p>
<p>JobGraph 生成时会进行算子链优化，将可以合并的算子放到同一个 Task 中执行：</p>
<pre><code class="language-java">// StreamingJobGraphGenerator.java
private void createChain(...) {
    // 判断是否可以 chain
    if (isChainable(currentOperator, downstreamOperator)) {
        // 合并到同一个 JobVertex
        chainedOperators.add(downstreamOperator);
    } else {
        // 创建新的 JobVertex
        createJobVertex(currentOperator);
    }
}

// 判断是否可以 chain 的条件
public static boolean isChainable(StreamEdge edge, StreamGraph streamGraph) {
    // 1. 下游算子只有一个输入
    // 2. 上下游算子在同一个 slot sharing group
    // 3. 上下游并行度相同
    // 4. 连接策略是 ALWAYS 或 HEAD
    // 5. 分区方式是 ForwardPartitioner
    // 6. 上下游算子都允许 chaining
    return downStreamOperator.getInEdges().size() == 1
        &amp;&amp; upStreamOperator.getSlotSharingGroup().equals(downStreamOperator.getSlotSharingGroup())
        &amp;&amp; upStreamOperator.getParallelism() == downStreamOperator.getParallelism()
        &amp;&amp; edge.getPartitioner() instanceof ForwardPartitioner
        &amp;&amp; upStreamOperator.getChainingStrategy() != ChainingStrategy.NEVER
        &amp;&amp; downStreamOperator.getChainingStrategy() != ChainingStrategy.HEAD;
}
</code></pre>
<p><strong>JobGraph 核心数据结构</strong>：</p>
<pre><code class="language-java">// JobGraph.java
public class JobGraph {
    private final JobID jobID;
    // 顶点：一个 JobVertex 对应一个或多个 chained 的算子
    private final Map&lt;JobVertexID, JobVertex&gt; taskVertices = new LinkedHashMap&lt;&gt;();
}

// JobVertex.java
public class JobVertex {
    private final JobVertexID id;
    private final List&lt;IntermediateDataSet&gt; results;      // 输出数据集
    private final List&lt;JobEdge&gt; inputs;                   // 输入边
    private int parallelism;                              // 并行度
    private String invokableClassName;                    // Task 类名
}
</code></pre>
<h3 id="第三阶段作业提交与调度">第三阶段：作业提交与调度</h3>
<h4 id="dispatcher-接收作业">Dispatcher 接收作业</h4>
<pre><code class="language-java">// Dispatcher.java
public CompletableFuture&lt;Acknowledge&gt; submitJob(JobGraph jobGraph) {
    // 1. 持久化 JobGraph
    jobGraphStore.putJobGraph(jobGraph);
    // 2. 创建 JobMaster
    runJob(jobGraph);
}

private void runJob(JobGraph jobGraph) {
    // 创建 JobManagerRunner，内部包含 JobMaster
    JobManagerRunner jobManagerRunner = createJobManagerRunner(jobGraph);
    jobManagerRunner.start();
}
</code></pre>
<h4 id="jobmaster-生成-executiongraph">JobMaster 生成 ExecutionGraph</h4>
<pre><code class="language-java">// JobMaster.java
public JobMaster(..., JobGraph jobGraph, ...) {
    // 核心：从 JobGraph 生成 ExecutionGraph
    this.executionGraph = createAndRestoreExecutionGraph(jobGraph);
}

private ExecutionGraph createExecutionGraph(JobGraph jobGraph) {
    // ExecutionGraphBuilder 构建 ExecutionGraph
    return ExecutionGraphBuilder.buildGraph(
        jobGraph,
        configuration,
        slotProvider,
        ...);
}
</code></pre>
<p><strong>ExecutionGraph 核心数据结构</strong>：</p>
<pre><code class="language-java">// ExecutionGraph.java
public class ExecutionGraph {
    // JobVertex -&gt; ExecutionJobVertex 的映射
    private final Map&lt;JobVertexID, ExecutionJobVertex&gt; tasks = new HashMap&lt;&gt;();
    // 所有的 Execution（Task 实例）
    private final Map&lt;ExecutionAttemptID, Execution&gt; currentExecutions = new HashMap&lt;&gt;();
}

// ExecutionJobVertex.java（对应 JobVertex）
public class ExecutionJobVertex {
    private final ExecutionVertex[] taskVertices;  // 并行度个 ExecutionVertex
}

// ExecutionVertex.java（对应一个并行实例）
public class ExecutionVertex {
    private final ExecutionJobVertex jobVertex;
    private final int subTaskIndex;      // 子任务索引
    private Execution currentExecution;  // 当前执行实例
}

// Execution.java（一次执行尝试）
public class Execution {
    private final ExecutionVertex vertex;
    private final ExecutionAttemptID attemptId;
    // CREATED -&gt; SCHEDULED -&gt; DEPLOYING -&gt; RUNNING -&gt; FINISHED
    private ExecutionState state;        
    private LogicalSlot assignedResource;  // 分配的 slot
}
</code></pre>
<p><strong>图的转换关系</strong>：</p>
<pre><code>StreamGraph          JobGraph              ExecutionGraph
-----------          --------              --------------
StreamNode    ---&gt;   JobVertex      ---&gt;   ExecutionJobVertex
(每个算子)           (chained算子)          (并行度个ExecutionVertex)
                                                    |
                                                    v
                                              Execution (实际执行)
</code></pre>
<h4 id="scheduler-调度-task">Scheduler 调度 Task</h4>
<pre><code class="language-java">// DefaultScheduler.java
public void startScheduling() {
    // 1. 分配 slot
    allocateSlots();
    // 2. 部署 Task
    deployTasks();
}

private void deployTasks(List&lt;ExecutionVertex&gt; vertices) {
    for (ExecutionVertex vertex : vertices) {
        // 获取分配的 slot
        LogicalSlot slot = vertex.getCurrentExecution().getAssignedResource();
        // 创建 TaskDeploymentDescriptor
        TaskDeploymentDescriptor tdd = createTaskDeploymentDescriptor(vertex);
        // 向 TaskManager 提交 Task
        slot.getTaskManagerGateway().submitTask(tdd);
    }
}
</code></pre>
<h3 id="第四阶段taskmanager-执行">第四阶段：TaskManager 执行</h3>
<h4 id="task-启动">Task 启动</h4>
<pre><code class="language-java">// TaskExecutor.java（TaskManager 的 RPC 端点）
public CompletableFuture&lt;Acknowledge&gt; submitTask(TaskDeploymentDescriptor tdd) {
    // 1. 创建 Task 对象
    Task task = new Task(tdd, ...);
    // 2. 注册到 TaskSlot
    taskSlotTable.addTask(task);
    // 3. 启动 Task 线程
    task.startTaskThread();
}

// Task.java
public void run() {
    // 1. 加载用户代码
    invokable = loadAndInstantiateInvokable(userCodeClassLoader, nameOfInvokableClass);
    // 2. 执行 Task
    invokable.invoke();
}
</code></pre>
<h4 id="streamtask-执行流程">StreamTask 执行流程</h4>
<p><code>StreamTask</code> 是所有流式 Task 的基类：</p>
<pre><code class="language-java">// StreamTask.java
public abstract class StreamTask&lt;OUT, OP extends StreamOperator&lt;OUT&gt;&gt; {
    
    public final void invoke() throws Exception {
        // 1. 初始化
        beforeInvoke();
        // 2. 执行（核心循环）
        runMailboxLoop();
        // 3. 清理
        afterInvoke();
    }
    
    // 初始化算子链
    protected void beforeInvoke() {
        // 创建 OperatorChain
        operatorChain = new OperatorChain&lt;&gt;(this, recordWriter);
        // 初始化所有算子
        operatorChain.initializeStateAndOpenOperators(createStreamTaskStateInitializer());
    }
    
    // 核心处理循环
    public void runMailboxLoop() {
        while (true) {
            // 处理邮件（checkpoint、timer 等）
            processMail();
            // 处理输入数据
            inputProcessor.processInput();
        }
    }
}
</code></pre>
<h4 id="数据处理流程">数据处理流程</h4>
<pre><code class="language-java">// StreamInputProcessor.java
public InputStatus processInput() {
    // 1. 从 InputGate 读取数据
    BufferOrEvent bufferOrEvent = inputGate.getNext();
    // 2. 反序列化
    StreamRecord&lt;IN&gt; record = deserializer.getNextRecord();
    // 3. 调用算子处理
    operator.processElement(record);
}

// StreamMap.java（以 map 算子为例）
public class StreamMap&lt;IN, OUT&gt; extends AbstractUdfStreamOperator&lt;OUT, MapFunction&lt;IN, OUT&gt;&gt; {
    
    @Override
    public void processElement(StreamRecord&lt;IN&gt; element) throws Exception {
        // 1. 调用用户函数
        OUT result = userFunction.map(element.getValue());
        // 2. 输出到下游
        output.collect(element.replace(result));
    }
}
</code></pre>
<h3 id="第五阶段checkpoint-机制">第五阶段：Checkpoint 机制</h3>
<h4 id="checkpoint-触发">Checkpoint 触发</h4>
<pre><code class="language-java">// CheckpointCoordinator.java
public void triggerCheckpoint(long timestamp) {
    // 1. 生成 checkpoint ID
    long checkpointId = checkpointIdCounter.getAndIncrement();
    // 2. 向所有 Source Task 发送 barrier
    for (ExecutionVertex sourceTask : sourceTasks) {
        sourceTask.getCurrentExecution().triggerCheckpoint(checkpointId, timestamp);
    }
}
</code></pre>
<h4 id="barrier-传播与对齐">Barrier 传播与对齐</h4>
<pre><code class="language-java">// CheckpointBarrierHandler.java
public void processBarrier(CheckpointBarrier barrier, int channelIndex) {
    // 1. 记录收到的 barrier
    barrierCount[channelIndex]++;
    // 2. 检查是否所有 channel 都收到了 barrier
    if (barrierCount.allReceived()) {
        // 3. 触发本地 checkpoint
        triggerCheckpoint(barrier.getId());
        // 4. 向下游发送 barrier
        output.emitBarrier(barrier);
    }
}
</code></pre>
<h4 id="状态快照">状态快照</h4>
<pre><code class="language-java">// StreamTask.java
public void triggerCheckpoint(long checkpointId) {
    // 1. 对所有算子做状态快照
    for (StreamOperator&lt;?&gt; operator : operatorChain.getAllOperators()) {
        operator.snapshotState(checkpointId);
    }
    // 2. 上报 checkpoint 完成
    reportCheckpointComplete(checkpointId);
}
</code></pre>
<h2 id="关键类速查表">关键类速查表</h2>
<table>
<thead>
<tr>
<th>阶段</th>
<th>关键类</th>
<th>职责</th>
</tr>
</thead>
<tbody>
<tr>
<td>Client</td>
<td><code>StreamExecutionEnvironment</code></td>
<td>用户程序入口，管理 transformations</td>
</tr>
<tr>
<td>Client</td>
<td><code>StreamGraphGenerator</code></td>
<td>生成 StreamGraph</td>
</tr>
<tr>
<td>Client</td>
<td><code>StreamingJobGraphGenerator</code></td>
<td>生成 JobGraph，算子链优化</td>
</tr>
<tr>
<td>Master</td>
<td><code>Dispatcher</code></td>
<td>接收作业，创建 JobMaster</td>
</tr>
<tr>
<td>Master</td>
<td><code>JobMaster</code></td>
<td>作业协调，生成 ExecutionGraph</td>
</tr>
<tr>
<td>Master</td>
<td><code>DefaultScheduler</code></td>
<td>调度 Task 到 TaskManager</td>
</tr>
<tr>
<td>Master</td>
<td><code>CheckpointCoordinator</code></td>
<td>触发和协调 checkpoint</td>
</tr>
<tr>
<td>Worker</td>
<td><code>TaskExecutor</code></td>
<td>TaskManager 的 RPC 端点</td>
</tr>
<tr>
<td>Worker</td>
<td><code>Task</code></td>
<td>执行单元，包装 StreamTask</td>
</tr>
<tr>
<td>Worker</td>
<td><code>StreamTask</code></td>
<td>流式 Task 基类，核心处理循环</td>
</tr>
<tr>
<td>Worker</td>
<td><code>OperatorChain</code></td>
<td>管理 chained 算子</td>
</tr>
</tbody>
</table>
<h2 id="调试技巧">调试技巧</h2>
<h3 id="关键断点位置">关键断点位置</h3>
<ol>
<li><strong>StreamGraph 生成</strong>：<code>StreamGraphGenerator.transform()</code></li>
<li><strong>JobGraph 生成</strong>：<code>StreamingJobGraphGenerator.createChain()</code></li>
<li><strong>作业提交</strong>：<code>Dispatcher.submitJob()</code></li>
<li><strong>Task 部署</strong>：<code>TaskExecutor.submitTask()</code></li>
<li><strong>数据处理</strong>：<code>StreamTask.processInput()</code></li>
<li><strong>Checkpoint</strong>：<code>CheckpointCoordinator.triggerCheckpoint()</code></li>
</ol>
<h3 id="日志配置">日志配置</h3>
<p>在 <code>log4j.properties</code> 中添加：</p>
<pre><code class="language-properties"># 查看 StreamGraph 生成
logger.graph.name = org.apache.flink.streaming.api.graph
logger.graph.level = DEBUG

# 查看调度过程
logger.scheduler.name = org.apache.flink.runtime.scheduler
logger.scheduler.level = DEBUG

# 查看 Checkpoint
logger.checkpoint.name = org.apache.flink.runtime.checkpoint
logger.checkpoint.level = DEBUG
</code></pre>
<h3 id="web-ui-观察点">Web UI 观察点</h3>
<p>访问 <code>http://localhost:8081</code>：</p>
<ol>
<li><strong>Running Jobs</strong> → 查看作业 DAG 图</li>
<li><strong>Task Managers</strong> → 查看 slot 分配情况</li>
<li><strong>Checkpoints</strong> → 查看 checkpoint 历史和耗时</li>
<li><strong>Back Pressure</strong> → 查看反压情况</li>
</ol>

</main>

  <footer>
  
<script src="https://utteranc.es/client.js"
        repo="qiref/qiref.github.io"
        issue-term="pathname"
        label="Comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>


<script>
(function() {
  const searchInput = document.getElementById('search-input');
  const searchResults = document.getElementById('search-results');
  if (!searchInput || !searchResults) return;
  
  let searchIndex = null;
  let activeIndex = -1;
  let isResultsVisible = false;

  
  async function loadSearchIndex() {
    if (searchIndex) return searchIndex;
    try {
      const response = await fetch('/index.json');
      const data = await response.json();
      searchIndex = data.pages || [];
      return searchIndex;
    } catch (e) {
      console.error('Failed to load search index:', e);
      return [];
    }
  }

  
  function search(query) {
    if (!searchIndex || !query.trim()) return [];
    const q = query.toLowerCase();
    return searchIndex.filter(page => {
      const title = (page.title || '').toLowerCase();
      const content = (page.content || '').toLowerCase();
      return title.includes(q) || content.includes(q);
    }).slice(0, 10);
  }

  
  function highlight(text, query) {
    if (!query) return text;
    const regex = new RegExp(`(${query.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')})`, 'gi');
    return text.replace(regex, '<mark>$1</mark>');
  }

  
  function showResults() {
    searchResults.style.display = 'block';
    isResultsVisible = true;
  }

  
  function hideResults() {
    searchResults.style.display = 'none';
    isResultsVisible = false;
    activeIndex = -1;
  }

  
  function updateActiveItem() {
    const items = searchResults.querySelectorAll('.search-result-item');
    items.forEach((item, index) => {
      if (index === activeIndex) {
        item.classList.add('active');
      } else {
        item.classList.remove('active');
      }
    });
  }

  
  function renderResults(results, query) {
    activeIndex = -1;
    if (!results.length) {
      hideResults();
      return;
    }
    const html = results.map(page => {
      const title = highlight(page.title || 'Untitled', query);
      let summary = page.summary || page.content || '';
      summary = summary.substring(0, 100) + (summary.length > 100 ? '...' : '');
      return `<a class="search-result-item" href="${page.url}">
        <div class="search-result-title">${title}</div>
        <div class="search-result-summary">${summary}</div>
      </a>`;
    }).join('');
    searchResults.innerHTML = html;
    showResults();
  }

  
  let debounceTimer;
  function debounce(fn, delay) {
    return function(...args) {
      clearTimeout(debounceTimer);
      debounceTimer = setTimeout(() => fn.apply(this, args), delay);
    };
  }

  
  searchInput.addEventListener('input', debounce(async function() {
    const query = this.value.trim();
    if (!query) {
      hideResults();
      return;
    }
    await loadSearchIndex();
    const results = search(query);
    renderResults(results, query);
  }, 200));

  
  searchInput.addEventListener('keydown', function(e) {
    if (!isResultsVisible) return;
    
    const items = searchResults.querySelectorAll('.search-result-item');
    const itemCount = items.length;
    if (itemCount === 0) return;

    switch (e.key) {
      case 'ArrowDown':
        e.preventDefault();
        e.stopPropagation();
        activeIndex = (activeIndex + 1) % itemCount;
        updateActiveItem();
        break;
      case 'ArrowUp':
        e.preventDefault();
        e.stopPropagation();
        activeIndex = activeIndex <= 0 ? itemCount - 1 : activeIndex - 1;
        updateActiveItem();
        break;
      case 'Enter':
        if (activeIndex >= 0 && items[activeIndex]) {
          e.preventDefault();
          window.location.href = items[activeIndex].href;
        }
        break;
      case 'Escape':
        e.preventDefault();
        hideResults();
        break;
    }
  });

  
  searchInput.addEventListener('focus', async function() {
    const query = this.value.trim();
    if (query) {
      await loadSearchIndex();
      const results = search(query);
      renderResults(results, query);
    }
  });

  
  document.addEventListener('click', function(e) {
    if (!searchInput.contains(e.target) && !searchResults.contains(e.target)) {
      hideResults();
    }
  });

  
  document.addEventListener('keydown', function(e) {
    if ((e.metaKey || e.ctrlKey) && e.key === 'k') {
      e.preventDefault();
      searchInput.focus();
      searchInput.select();
    }
  });
})();
</script>
  
  <hr/>
  © powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/yihui/hugo-xmin">Xmin</a>  2017 &ndash; 2025 | <a href="https://github.com/qiref">Github</a>
  
  </footer>
  </body>
</html>


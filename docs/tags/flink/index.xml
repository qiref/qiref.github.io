<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Flink on 大道至简</title>
    <link>https://qiref.github.io/tags/flink/</link>
    <description>Recent content in Flink on 大道至简</description>
    <generator>Hugo</generator>
    <language>cn-zh</language>
    <lastBuildDate>Tue, 28 Mar 2023 20:31:01 +0800</lastBuildDate>
    <atom:link href="https://qiref.github.io/tags/flink/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Flink内存模型</title>
      <link>https://qiref.github.io/post/2023/03/28/flink%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Tue, 28 Mar 2023 20:31:01 +0800</pubDate>
      <guid>https://qiref.github.io/post/2023/03/28/flink%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;h2 id=&#34;java-堆外内存&#34;&gt;Java 堆外内存&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import sun.nio.ch.DirectBuffer;&#xA;import java.nio.ByteBuffer;&#xA;import java.util.concurrent.TimeUnit;&#xA;&#xA;public class OutHeapMem {&#xA;    public static void main(String[] args) throws Exception {&#xA;        // 分配 1G 直接内存&#xA;        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024 * 1024 * 1024);&#xA;        TimeUnit.SECONDS.sleep(30);&#xA;&#xA;        System.out.println(&amp;quot;clean start&amp;quot;);&#xA;        // 清除直接内存&#xA;        ((DirectBuffer) byteBuffer).cleaner().clean();&#xA;        System.out.println(&amp;quot;clean finished&amp;quot;);&#xA;&#xA;        TimeUnit.SECONDS.sleep(30);&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;# 分配内存&#xA;Memory                                  used         total        max           usage&#xA;heap                                    21M          165M         3641M         0.59%&#xA;ps_eden_space                           3M           64M          1344M         0.29%&#xA;ps_survivor_space                       0K           10752K       10752K        0.00%&#xA;ps_old_gen                              17M          91M          2731M         0.64%&#xA;nonheap                                 28M          28M          -1            96.89%&#xA;code_cache                              5M           5M           240M          2.11%&#xA;metaspace                               20M          21M          -1            97.00%&#xA;compressed_class_space                  2M           2M           1024M         0.25%&#xA;+direct                                 1024M        1024M        -             100.00%&#xA;mapped                                  0K           0K           -             0.00% &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;# 释放内存&#xA;Memory                                  used         total        max           usage&#xA;heap                                    21M          165M         3641M         0.60%&#xA;ps_eden_space                           4M           64M          1344M         0.32%&#xA;ps_survivor_space                       0K           10752K       10752K        0.00%&#xA;ps_old_gen                              17M          91M          2731M         0.64%&#xA;nonheap                                 27M          28M          -1            96.79%&#xA;code_cache                              5M           5M           240M          2.09%&#xA;metaspace                               20M          21M          -1            97.03%&#xA;compressed_class_space                  2M           2M           1024M         0.25%&#xA;-direct                                 0K           0K           -             0.00%&#xA;mapped                                  0K           0K           -             0.00%&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;通过 arthas 分析，分配直接内存会在 direct 开辟内存空间，表明是在堆外分配的内存空间；虽然 byteBuffer 指向了 direct memory，但是这个对象引用还在 heap 中，当 byteBuffer 对象引用 被 GC 算法回收掉之后，byteBuffer 指向的内存空间也会被释放；&lt;/p&gt;</description>
    </item>
    <item>
      <title>Flink类加载机制</title>
      <link>https://qiref.github.io/post/2023/03/24/flink%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Fri, 24 Mar 2023 16:13:22 +0800</pubDate>
      <guid>https://qiref.github.io/post/2023/03/24/flink%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</guid>
      <description>&lt;h2 id=&#34;flink-类加载配置说明&#34;&gt;flink 类加载配置说明&lt;/h2&gt;&#xA;&lt;p&gt;Flink 作为基于 JVM 的框架，在 flink-conf.yaml 中提供了控制类加载策略的参数 classloader.resolve-order，可选项有 child-first（默认）和 parent-first。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Key&lt;/th&gt;&#xA;          &lt;th&gt;Default&lt;/th&gt;&#xA;          &lt;th&gt;Type&lt;/th&gt;&#xA;          &lt;th&gt;Description&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;classloader.resolve-order&lt;/td&gt;&#xA;          &lt;td&gt;&amp;ldquo;child-first&amp;rdquo;&lt;/td&gt;&#xA;          &lt;td&gt;String&lt;/td&gt;&#xA;          &lt;td&gt;Defines the class resolution strategy when loading classes from user code, meaning whether to first check the user code jar (&amp;ldquo;child-first&amp;rdquo;) or the application classpath (&amp;ldquo;parent-first&amp;rdquo;). The default settings indicate to load classes first from the user code jar, which means that user code jars can include and load different dependencies than Flink uses (transitively).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;classloader.parent-first-patterns.default&lt;/td&gt;&#xA;          &lt;td&gt;&amp;ldquo;java.&amp;rdquo;;&lt;br&gt;&amp;ldquo;scala.&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.apache.flink.&amp;rdquo;;&lt;br&gt;&amp;ldquo;com.esotericsoftware.kryo&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.apache.hadoop.&amp;rdquo;;&lt;br&gt;&amp;ldquo;javax.annotation.&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.xml&amp;rdquo;;&lt;br&gt;&amp;ldquo;javax.xml&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.apache.xerces&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.w3c&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.rocksdb.&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.slf4j&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.apache.log4j&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.apache.logging&amp;rdquo;;&lt;br&gt;&amp;ldquo;org.apache.commons.logging&amp;rdquo;;&lt;br&gt;&amp;ldquo;ch.qos.logback&amp;rdquo;&lt;/td&gt;&#xA;          &lt;td&gt;List&lt;String&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A (semicolon-separated) list of patterns that specifies which classes should always be resolved through the parent ClassLoader first. A pattern is a simple prefix that is checked against the fully qualified class name. This setting should generally not be modified. To add another pattern we recommend to use &amp;ldquo;classloader.parent-first-patterns.additional&amp;rdquo; instead.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;classloader.parent-first-patterns.additional&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;List&lt;String&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A (semicolon-separated) list of patterns that specifies which classes should always be resolved through the parent ClassLoader first. A pattern is a simple prefix that is checked against the fully qualified class name. These patterns are appended to &amp;ldquo;classloader.parent-first-patterns.default&amp;rdquo;.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;classloader.fail-on-metaspace-oom-error&lt;/td&gt;&#xA;          &lt;td&gt;true&lt;/td&gt;&#xA;          &lt;td&gt;Boolean&lt;/td&gt;&#xA;          &lt;td&gt;Fail Flink JVM processes if &amp;lsquo;OutOfMemoryError: Metaspace&amp;rsquo; is thrown while trying to load a user code class.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;classloader.check-leaked-classloader&lt;/td&gt;&#xA;          &lt;td&gt;true&lt;/td&gt;&#xA;          &lt;td&gt;Boolean&lt;/td&gt;&#xA;          &lt;td&gt;Fails attempts at loading classes if the user classloader of a job is used after it has terminated. This is usually caused by the classloader being leaked by lingering threads or misbehaving libraries, which may also result in the classloader being used by other jobs. This check should only be disabled if such a leak prevents further jobs from running.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;parent-first-类加载策略&#34;&gt;parent-first 类加载策略&lt;/h2&gt;&#xA;&lt;p&gt;ParentFirstClassLoader 和 ChildFirstClassLoader 类的父类均为 FlinkUserCodeClassLoader 抽象类：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Flink反压</title>
      <link>https://qiref.github.io/post/2023/03/23/flink%E5%8F%8D%E5%8E%8B/</link>
      <pubDate>Thu, 23 Mar 2023 16:37:37 +0800</pubDate>
      <guid>https://qiref.github.io/post/2023/03/23/flink%E5%8F%8D%E5%8E%8B/</guid>
      <description>&lt;h2 id=&#34;什么是反压&#34;&gt;什么是反压&lt;/h2&gt;&#xA;&lt;p&gt;如果你看到一个 Task 发生 &lt;strong&gt;反压警告&lt;/strong&gt;（例如： &lt;code&gt;High&lt;/code&gt;），意味着它生产数据的速率比下游 Task 消费数据的速率要快。 在工作流中数据记录是从上游向下游流动的（例如：从 Source 到 Sink）。反压沿着相反的方向传播，沿着数据流向上游传播。&lt;/p&gt;&#xA;&lt;p&gt;以一个简单的 &lt;code&gt;Source -&amp;gt; Sink&lt;/code&gt; Job 为例。如果看到 &lt;code&gt;Source&lt;/code&gt; 发生了警告，意味着 &lt;code&gt;Sink&lt;/code&gt; 消费数据的速率比 &lt;code&gt;Source&lt;/code&gt; 生产数据的速率要慢。 &lt;code&gt;Sink&lt;/code&gt; 正在向上游的 &lt;code&gt;Source&lt;/code&gt; 算子产生反压。&lt;/p&gt;&#xA;&lt;p&gt;Task（SubTask）的每个并行实例都可以用三个一组的指标评价：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;backPressureTimeMsPerSecond&lt;/code&gt;，subtask 被反压的时间&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;idleTimeMsPerSecond&lt;/code&gt;，subtask 等待某类处理的时间&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;busyTimeMsPerSecond&lt;/code&gt;，subtask 实际工作时间 在任何时间点，这三个指标相加都约等于&lt;code&gt;1000ms&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;指标值说明：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;OK&lt;/strong&gt;: 0 &amp;lt;= 比例 &amp;lt;= 0.10&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;LOW&lt;/strong&gt;: 0.10 &amp;lt; 比例 &amp;lt;= 0.5&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;HIGH&lt;/strong&gt;: 0.5 &amp;lt; 比例 &amp;lt;= 1&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;反压问题定位&#34;&gt;反压问题定位&lt;/h2&gt;&#xA;&lt;p&gt;可以看各个operator的metrics的指标，比如：buffers.outPoolUsage、buffers.inPoolUsage、buffers.inputFloatingBuffersUsage、buffers.inputExclusiveBuffersUsage；&lt;/p&gt;&#xA;&lt;p&gt;接收端共用一个LocalBufferPool，接收端每个Channel在初始化阶段都会分配固定数量的Buffer(Exclusive Buffer)。如果某一时刻接收端接受到的数量太多，Exclusive Buffer就会耗尽，此时就会向BufferPool申请剩余的Floating Buffer（除了Exclusive Buffer，其他的都是Floating Buffer,备用Buffer）；&lt;code&gt;inPoolUsage = floatingBuffersUsage + exclusiveBuffersUsage&lt;/code&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;若 inPoolUsage 低，而 outPoolUsage 低，则说明完全没有背压现象。&lt;/li&gt;&#xA;&lt;li&gt;若 inPoolUsage 低，而 outPoolUsage 高，则说明处于临时状态，可能是背压刚开始，也可能是刚结束，需要再观察。&lt;/li&gt;&#xA;&lt;li&gt;若 inPoolUsage 高，而 outPoolUsage 低，那么通常情况下这个算子就是背压的根源了。&lt;/li&gt;&#xA;&lt;li&gt;若 inPoolUsage 高，而 outPoolUsage 高，则说明这个算子是被其他下游算子反压而来的，并不是元凶。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;在反压定位过程中，建议关闭 Operator Chaining 优化，这样所有的算子可以单独拆分出来，不会相互干扰：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Flink Append流、Retract流、Upsert流</title>
      <link>https://qiref.github.io/post/2022/03/13/flink-append%E6%B5%81retract%E6%B5%81upsert%E6%B5%81/</link>
      <pubDate>Sun, 13 Mar 2022 11:16:23 +0000</pubDate>
      <guid>https://qiref.github.io/post/2022/03/13/flink-append%E6%B5%81retract%E6%B5%81upsert%E6%B5%81/</guid>
      <description>&lt;p&gt;摘要： 介绍 Flink 中 Append流、Retract流、Upsert流的含义。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#append%E6%B5%81&#34;&gt;Append流&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#retract%E6%B5%81&#34;&gt;Retract流&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#upsert%E6%B5%81&#34;&gt;Upsert流&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;append流&#34;&gt;Append流&lt;/h2&gt;&#xA;&lt;p&gt;在 Append 流中，仅通过 &lt;code&gt;INSERT&lt;/code&gt; 操作修改的动态表，可以通过输出插入的行转换为流。&lt;/p&gt;&#xA;&lt;h2 id=&#34;retract流&#34;&gt;Retract流&lt;/h2&gt;&#xA;&lt;p&gt;retract 流包含两种类型的 message： add messages 和 retract messages 。&lt;/p&gt;&#xA;&lt;p&gt;通过将INSERT 操作编码为 add message、将 &lt;code&gt;DELETE&lt;/code&gt; 操作编码为 retract message、将 &lt;code&gt;UPDATE&lt;/code&gt; 操作编码为更新(先前)行的 retract message 和更新(新)行的 add message，将动态表转换为 retract 流。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;OPERATOR&lt;/th&gt;&#xA;          &lt;th&gt;ENCODE&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;insert&lt;/td&gt;&#xA;          &lt;td&gt;add&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;update&lt;/td&gt;&#xA;          &lt;td&gt;retract -&amp;gt; add&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;delete&lt;/td&gt;&#xA;          &lt;td&gt;retract&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;upsert流&#34;&gt;Upsert流&lt;/h2&gt;&#xA;&lt;p&gt;upsert 流包含两种类型的 message： upsert messages 和delete messages。&lt;/p&gt;&#xA;&lt;p&gt;转换为 upsert 流的动态表需要(可能是组合的)唯一键。通过将 &lt;code&gt;INSERT&lt;/code&gt; 和 &lt;code&gt;UPDATE&lt;/code&gt; 操作编码为 upsert message，将 &lt;code&gt;DELETE&lt;/code&gt; 操作编码为 delete message ，将具有唯一键的动态表转换为流。消费流的算子需要知道唯一键的属性，以便正确地应用 message。与 retract 流的主要区别在于 &lt;code&gt;UPDATE&lt;/code&gt; 操作是用单个 message 编码的，因此效率更高。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Flink Checkpoint机制</title>
      <link>https://qiref.github.io/post/2022/03/04/flink-checkpoint%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Fri, 04 Mar 2022 11:16:23 +0000</pubDate>
      <guid>https://qiref.github.io/post/2022/03/04/flink-checkpoint%E6%9C%BA%E5%88%B6/</guid>
      <description>&lt;p&gt;摘要： 如果把运行中的 Flink 程序比做一条河流，Checkpoint 就是一个相机，定期地对河流进行拍照，记录河水的状态。本文以自顶向下的视角，从理论到实现，分析 Flink 中的 Checkpoint 机制；&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80&#34;&gt;理论基础&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#asynchronous-barrier-snapshotting&#34;&gt;asynchronous barrier snapshotting&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4&#34;&gt;算法步骤&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#%E7%AE%97%E6%B3%95%E5%9C%A8-flink-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0&#34;&gt;算法在 Flink 中的实现&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#flink-checkpoint-%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B&#34;&gt;Flink Checkpoint 整体流程&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#flink-checkpoint-barrier-alignment&#34;&gt;Flink Checkpoint Barrier Alignment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#flink-checkpoint-%E4%BD%BF%E7%94%A8&#34;&gt;Flink Checkpoint 使用&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#flink-job-%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5&#34;&gt;Flink Job 重启策略&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#flink-job-%E5%BC%80%E5%90%AF-checkpoint&#34;&gt;Flink Job 开启 Checkpoint&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;理论基础&#34;&gt;理论基础&lt;/h2&gt;&#xA;&lt;h3 id=&#34;asynchronous-barrier-snapshotting&#34;&gt;asynchronous barrier snapshotting&lt;/h3&gt;&#xA;&lt;p&gt;Flink Checkpoint 机制是异步屏障快照（asynchronous barrier snapshotting, ABS）算法的一种实现，而 ABS 算法基于 &lt;a href=&#34;https://archieyao.github.io/posts/2023-05-08-chandy-lamport%E7%AE%97%E6%B3%95/&#34;&gt;Chandy-Lamport&lt;/a&gt; 的变种，但数据模型是还是基于  Chandy-Lamport；&lt;/p&gt;&#xA;&lt;p&gt;在 flink 中，作业算子被抽象为 DAG，节点为 operator，边是每一个 operator 的 stream（channel），与 Chandy-Lamport 的数据模型正好吻合；&lt;/p&gt;&#xA;&lt;p&gt;ABS 算法把 Chandy-Lamport 中的 marker 消息换成了 barrier，作用是一致的，都是切分 snapshot；&lt;/p&gt;&#xA;&lt;p&gt;ABS 算法 中 asynchronous 是异步的意思，当算子收齐 barrier 并触发快照之后，不会等待快照数据全部写入状态后端，而是一边后台写入，一边立刻继续处理数据流，并将 barrier 发送到下游，实现了最小化延迟。当然，引入异步性之后，所有有状态的算子都需要上报 ack，否则 JobManager 就无法确认一次 snapshot 是否完成。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Flink时间语义</title>
      <link>https://qiref.github.io/post/2022/02/25/flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89/</link>
      <pubDate>Fri, 25 Feb 2022 11:16:23 +0000</pubDate>
      <guid>https://qiref.github.io/post/2022/02/25/flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89/</guid>
      <description>&lt;p&gt;摘要： 理解流处理中的时间语义，处理时间和事件时间。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/stream-time.png&#34; alt=&#34;stream-time&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;如图，在无界数据中，随着时间推移，数据一直产生，但真实情况中，往往在一段时间内的数据都是不均匀的，往往会出现意外的情况，比如在地铁无信号的情况下，数据虽然产生，但是会有一段时间延迟才会到达消息队列，例如虚线框中的数据。&lt;/p&gt;&#xA;&lt;h2 id=&#34;处理时间&#34;&gt;处理时间&lt;/h2&gt;&#xA;&lt;p&gt;处理时间就是流计算处理程序的机器本地时间，按照这种时间语义，在流计算的时间窗口中，上述例子中的数据会按这样分布：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/process-time.png&#34; alt=&#34;process-time&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;基于本地时间，在第一分钟，流处理程序只收到了 &lt;code&gt;15&lt;/code&gt;、&lt;code&gt;18&lt;/code&gt; 两个数据，后续数据由于网络原因，在 8:01:00 之后才到达流计算程序，所以后续数据在下一个时间窗口内。&lt;/p&gt;&#xA;&lt;h2 id=&#34;事件时间&#34;&gt;事件时间&lt;/h2&gt;&#xA;&lt;p&gt;事件时间就是事件的发生时间，这个时间通常会在数据中，按照这种时间语义，在流计算的时间窗口中，上述例子中的数据会按这样分布：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/event-time.png&#34; alt=&#34;event-time&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;基于事件时间，在第一分钟，数据应该是：&lt;code&gt;15&lt;/code&gt; &lt;code&gt;18&lt;/code&gt; &lt;code&gt;9&lt;/code&gt; &lt;code&gt;10&lt;/code&gt; ，在第二分钟，数据应该是：&lt;code&gt;11&lt;/code&gt; 。&lt;/p&gt;&#xA;&lt;h2 id=&#34;watermark&#34;&gt;watermark&lt;/h2&gt;&#xA;&lt;p&gt;由于事件时间的窗口和事件相关，那么如果下一个事件还未到达，流计算程序是否就无限等待呢？&lt;/p&gt;&#xA;&lt;p&gt;为了解决这个问题，flink 引入 watermark 的概念，假如定义 watermark 为 T，那么在每一个时间窗口中，T 都会单调递增 &lt;code&gt;T &amp;lt; T1&lt;/code&gt;，并且下一个时间窗口中的事件时间必须大于 &lt;code&gt;T1&lt;/code&gt;，那么每一个时间窗口的数据就是介于 &lt;code&gt;T-T1&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Flink基本架构</title>
      <link>https://qiref.github.io/post/2022/02/23/flink%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Wed, 23 Feb 2022 11:16:23 +0000</pubDate>
      <guid>https://qiref.github.io/post/2022/02/23/flink%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/</guid>
      <description>&lt;p&gt;摘要： 鸟瞰 Flink 架构，分析 Flink 内部组件工作机制。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#flink-%E6%9E%B6%E6%9E%84%E5%9B%BE&#34;&gt;Flink 架构图&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A%E6%B5%81%E7%A8%8B&#34;&gt;提交作业流程&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#flink-%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F&#34;&gt;Flink 集群模式&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#jobmanager&#34;&gt;JobManager&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#taskmanager&#34;&gt;Taskmanager&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#%E7%AE%97%E5%AD%90%E9%93%BE&#34;&gt;算子链&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#slot&#34;&gt;Slot&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#task-%E6%95%B0%E6%8D%AE%E4%BA%A4%E6%8D%A2%E7%AD%96%E7%95%A5&#34;&gt;task 数据交换策略&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;flink-架构图&#34;&gt;Flink 架构图&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/flink-struct.svg&#34; alt=&#34;Flink架构图&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;一个完整的 Flink 集群由一个 Jobmanager 和若干个 Taskmanager 组成，Jobmanager 主要负责调度 task 以及 协调 Checkpoint。Taskmanager 则负责具体的 task 执行，以及数据流的交换。&lt;/p&gt;&#xA;&lt;p&gt;可以通过多种方式启动 JobManager 和 TaskManager：直接在机器上作为standalone 集群启动、在容器中启动、或者通过YARN等资源框架管理并启动。TaskManager 连接到 JobManagers，宣布自己可用，并被分配工作。&lt;/p&gt;&#xA;&lt;h2 id=&#34;提交作业流程&#34;&gt;提交作业流程&lt;/h2&gt;&#xA;&lt;p&gt;以一个作业提交的流程来说明 Flink 各个组件是如何交互和工作的：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/flink-struct-1.svg&#34; alt=&#34;提交作业流程&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;flink-集群模式&#34;&gt;Flink 集群模式&lt;/h2&gt;&#xA;&lt;p&gt;Flink 集群类型一般有以下几种：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Flink Session 集群&lt;/p&gt;&#xA;&lt;p&gt;这种模式下，集群自创建开始，最后到集群生命周期结束，不受作业因素影响； 集群下的多个作业共享 内存、网络、磁盘等资源，如果集群出现异常，该集群下的所有作业都会收到影响。&lt;/p&gt;&#xA;&lt;p&gt;优点：提交作业速度很快，无需提前申请资源； 并且资源利用率较高。&lt;/p&gt;&#xA;&lt;p&gt;缺点：作业之间隔离性较差，横向扩展不太方便。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Flink job 集群&lt;/p&gt;&#xA;&lt;p&gt;这种模式也称 pre-job 模式，集群交由 资源管理器托管，例如 Yarn ，需要运行作业，第一步申请资源，启动一个 Flink 集群，第二步提交作业，这种模式下，每个作业会独享一个 Flink 集群。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Flink WordCount</title>
      <link>https://qiref.github.io/post/2022/02/22/flink-wordcount/</link>
      <pubDate>Tue, 22 Feb 2022 18:16:23 +0000</pubDate>
      <guid>https://qiref.github.io/post/2022/02/22/flink-wordcount/</guid>
      <description>&lt;p&gt;摘要：Flink 从零开始，下载集群并运行 WordCount Job。 完整代码地址： &lt;a href=&#34;https://github.com/ArchieYao/flink-learning/tree/main/hello-world&#34;&gt;https://github.com/ArchieYao/flink-learning/tree/main/hello-world&lt;/a&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;flink-本地模式集群安装&#34;&gt;Flink 本地模式集群安装&lt;/h2&gt;&#xA;&lt;p&gt;运行Flink，需提前安装好 Java 8 或者 Java 11。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget https://dlcdn.apache.org/flink/flink-1.14.3/flink-1.14.3-bin-scala_2.12.tgz&#xA;tar -zxvf flink-1.14.3-bin-scala_2.12.tgz&#xA;cd flink-1.14.3&#xA;./bin/start-cluster.sh&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;运行成功后，可以在 IP:8081 访问 Flink-UI&lt;/p&gt;&#xA;&lt;h2 id=&#34;flink-word-count-job&#34;&gt;Flink Word Count job&lt;/h2&gt;&#xA;&lt;p&gt;source 是多段文本，类型： DataSource&lt;String&gt; ，经过 flatMap，切分为每个单词，然后转换为：(val,n) 的数据，然后根据 val 分组统计，得出 sum(n) 的值。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String[] args) throws Exception {&#xA;    // 创建Flink任务运行环境&#xA;    final ExecutionEnvironment executionEnvironment =&#xA;            ExecutionEnvironment.getExecutionEnvironment();&#xA;&#xA;    // 创建DataSet，数据是一行一行文本&#xA;    DataSource&amp;lt;String&amp;gt; text =&#xA;            executionEnvironment.fromElements(&#xA;                    &amp;quot;Licensed to the Apache Software Foundation (ASF) under one&amp;quot;,&#xA;                    &amp;quot;or more contributor license agreements.  See the NOTICE file&amp;quot;,&#xA;                    &amp;quot;distributed with this work for additional information&amp;quot;,&#xA;                    &amp;quot;regarding copyright ownership.  The ASF licenses this file&amp;quot;,&#xA;                    &amp;quot;to you under the Apache License, Version 2.0 (the&amp;quot;);&#xA;&#xA;    // 通过Flink内置转换函数进行计算&#xA;    AggregateOperator&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; sum =&#xA;            text.flatMap(&#xA;                            new FlatMapFunction&amp;lt;String, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;() {&#xA;                                @Override&#xA;                                public void flatMap(&#xA;                                        String value,&#xA;                                        Collector&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; collector)&#xA;                                        throws Exception {&#xA;                                    String[] split = value.split(&amp;quot;\\W+&amp;quot;);&#xA;                                    for (String s : split) {&#xA;                                        if (s.length() &amp;gt; 0) {&#xA;                                            collector.collect(new Tuple2&amp;lt;&amp;gt;(s, 1));&#xA;                                            // TimeUnit.SECONDS.sleep(5);&#xA;                                        }&#xA;                                    }&#xA;                                }&#xA;                            })&#xA;                    .groupBy(0)&#xA;                    .sum(1);&#xA;&#xA;    // 打印结果&#xA;    sum.print();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Job 可以直接运行，也可以提交到 Flink 集群中运行。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper on 大道至简</title>
    <link>https://qiref.github.io/tags/paper/</link>
    <description>Recent content in Paper on 大道至简</description>
    <generator>Hugo</generator>
    <language>cn-zh</language>
    <lastBuildDate>Fri, 13 Oct 2023 11:46:21 +0800</lastBuildDate>
    <atom:link href="https://qiref.github.io/tags/paper/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Log Structured Merge Tree</title>
      <link>https://qiref.github.io/post/2023/10/13/log-structured-merge-tree/</link>
      <pubDate>Fri, 13 Oct 2023 11:46:21 +0800</pubDate>
      <guid>https://qiref.github.io/post/2023/10/13/log-structured-merge-tree/</guid>
      <description>&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;Log Structured Merge Tree&lt;/code&gt;, 其本质上是一种存储数据的方式,通常用于各种存储系统的底层数据结构,通过尽可能减少磁盘随机IO来提升写入性能, 适用于写多读少的场景.&lt;/p&gt;&#xA;&lt;h3 id=&#34;随机写和顺序写&#34;&gt;随机写和顺序写&lt;/h3&gt;&#xA;&lt;p&gt;对于一个存储系统而言, 不可避免地需要写入文件到磁盘, 对于常规的写来说, 每来一条数据写一次文件, 数据可能是 &lt;code&gt;add update delete&lt;/code&gt;, 需要频繁操作文件, 每一次写都是一次随机 IO; 为了提高写入速度, &lt;code&gt;LSM Tree&lt;/code&gt; 并不是每一次写操作都把文件写到磁盘, 而是将数据在内存中更新，当内存中的数据达到一定的阈值时，才将这部分数据真正刷新到磁盘文件中. 以这种方式尽可能让每次磁盘 IO 都是顺序写;&lt;/p&gt;&#xA;&lt;h3 id=&#34;思路&#34;&gt;思路&lt;/h3&gt;&#xA;&lt;p&gt;基于减少磁盘的随机 IO 来提升整体存储系统的写入性能这一背景, 很自然可以推导出用批量写入的方式, 要想批量写入, 就需要在内存维护最近写入的数据, 达到阈值之后生成一个文件写入到磁盘, 但是这样又会存在新的问题:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果某一条数据已经写入到磁盘文件, 后续又有更新, 怎么处理呢?&lt;/li&gt;&#xA;&lt;li&gt;内存中维护的临时数据, 如果还未来得及写入磁盘, 服务挂了, 重新启动时, 历史写入的数据如何恢复?&lt;/li&gt;&#xA;&lt;li&gt;每次内存中数据达到阈值,写一个整个文件到磁盘,那么最终会生成大量的文件, 如何解决?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;解决问题1, 为了优化这种更新的写入, 可以采用数据版本的做法, 或者给数据增加标志, 然后定期合并, 当然, 这也是以空间换时间, 相同的数据存储了多次, 以提升写入性能; 与此同时, 在数据读取时,由于写入的逻辑改变, 一条数据可能会存在于多个文件中, 因此在读取时, 需要返回最新的数据, 在读取到多条数据时,需要对多条数据进行合取最新;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;解决问题2, 在业界比较标准的做法是 &lt;code&gt;WAL&lt;/code&gt;, &lt;code&gt;WAL&lt;/code&gt; 的基本原理是在执行数据修改操作之前，先将这些操作记录在日志（log）文件中, 以确保在发生故障或崩溃时，可以借助日志进行恢复并保持数据的一致性;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;解决问题3, 为了避免大量文件, 可以对文件进行定期合并, 当数据还在内存中时, 可以借助跳表或者 &lt;code&gt;B+Tree&lt;/code&gt; 等数据结构保证内存中数据的顺序性, 在写文件时, 由于数据是有序的, 在文件合并时,很自然可以借助归并排序保证合并之后的数据的有序性, 而有序性又能天然提高查询效率.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Skip Lists 阅读笔记</title>
      <link>https://qiref.github.io/post/2023/10/01/skip-lists-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Sun, 01 Oct 2023 22:05:38 +0800</pubDate>
      <guid>https://qiref.github.io/post/2023/10/01/skip-lists-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;h2 id=&#34;算法介绍&#34;&gt;算法介绍&lt;/h2&gt;&#xA;&lt;p&gt;《Skip Lists: A Probabilistic Alternative to Balanced Trees》 论文标题翻译就是 跳表: 平衡树的概率性替代方案; 跳表是一种可以用来代替平衡树的数据结构。跳表使用概率平衡而不是严格强制的平衡，因此跳跃列表中的插入和删除算法比平衡树的等效算法要简单得多并且速度明显更快。&lt;/p&gt;&#xA;&lt;p&gt;从论文的标题和介绍, 基本上就能知道跳表是一种怎么样的数据结构, 为了解决平衡树实现的复杂性, 提供一种概率性平衡的数据结构,作为平衡树的平替数据结构, 查询和插入时间复杂度是 &lt;code&gt;O(log n)&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;算法流程&#34;&gt;算法流程&lt;/h2&gt;&#xA;&lt;h3 id=&#34;基本原理&#34;&gt;基本原理&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/skiplist-1.svg&#34; alt=&#34;skiplist-1&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;节点结构：跳表由多个层级组成，每个层级都是一个有序链表。每个节点包含一个值和多个指向下一层级节点的指针。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;层级索引：跳表的最底层是一个普通的有序链表，每个节点都连接到下一个节点。而在更高的层级，节点以一定的概率连接到更远的节点，形成了一种“跳跃”的效果。这些连接被称为“跳跃指针”，它们允许我们在查找时可以快速地跳过一些节点。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;查找操作：从跳表的顶层开始，我们沿着每个层级向右移动，直到找到目标值或找到一个大于目标值的节点。然后我们进入下一层级继续查找，直到最底层。这种方式可以在平均情况下实现快速的查找，时间复杂度为 O(log n)。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;插入和删除操作：在插入新节点时，我们首先执行查找操作，找到合适的插入位置。然后我们在每个层级上插入新节点，并根据一定的概率决定是否要为该节点添加跳跃指针。删除操作类似，我们首先找到要删除的节点，然后将其从每个层级中移除。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;查询&#34;&gt;查询&lt;/h3&gt;&#xA;&lt;p&gt;&lt;code&gt;level&lt;/code&gt; 表示跳表的层级, 而 &lt;code&gt;forward[i]&lt;/code&gt; 是每一个层级的链表.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;Search(list, searchKey)&#xA;    x := list→header&#xA;    // 从跳表的顶层开始,遍历到第一层&#xA;    for i := list→level downto 1 do&#xA;        while x→forward[i]→key &amp;lt; searchKey do&#xA;            x := x→forward[i]&#xA;    // x→key &amp;lt; searchKey ≤ x→forward[1]→key&#xA;    // 最终的结果从跳表最底层获取&#xA;    x := x→forward[1]&#xA;    if x→key = searchKey then &#xA;        return x→value&#xA;    else &#xA;        return failure&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;写入&#34;&gt;写入&lt;/h3&gt;&#xA;&lt;p&gt;由跳表的定义得出, 跳表的上一层级相当于下一层级的索引, 如果需要构建多级的索引, 首先需要解决: &lt;em&gt;当前node是否应该索引到上一层级?&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>DBLog 阅读笔记</title>
      <link>https://qiref.github.io/post/2023/08/09/dblog-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 09 Aug 2023 10:39:17 +0800</pubDate>
      <guid>https://qiref.github.io/post/2023/08/09/dblog-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;&#xA;&lt;p&gt;论文原名: &lt;code&gt;DBLog: A Watermark Based Change-Data-Capture Framework&lt;/code&gt; , 基于 &lt;code&gt;Watermark&lt;/code&gt; 的 &lt;code&gt;Change-Data-Capture&lt;/code&gt;(数据库实时捕获已提交的变更记录) 框架, 本质上是解决数据库同步(全量+增量)的框架, &lt;code&gt;Watermark&lt;/code&gt; 是框架使用的一种手段, 在源表中创建表,生成唯一 uuid 并更新表数据, 在源表中就会生成一条变更记录,记作 &lt;code&gt;Watermark&lt;/code&gt; 的变更记录, 通过 &lt;code&gt;High Watermark&lt;/code&gt; 和 &lt;code&gt;Low Watermark &lt;/code&gt; 将变更记录分割, 保证 select chunk 数据包含了增量的变更记录.&lt;/p&gt;&#xA;&lt;p&gt;框架整体架构如下:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/DBLog-1.svg&#34; alt=&#34;DBLog-1&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;框架特点:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;按顺序处理捕获到的 &lt;code&gt;changelog&lt;/code&gt;;&lt;/li&gt;&#xA;&lt;li&gt;转储可以随时进行，跨所有表，针对一个特定的表或者针对一个表的具体主键;&lt;/li&gt;&#xA;&lt;li&gt;以块(chunk)的形式获取转储，日志与转储事件交错。通过这种方式，&lt;code&gt;changelog&lt;/code&gt; 可以与转储处理一起进行。如果进程终止，它可以在最后一个完成的块之后恢复，而不需要从头开始。这还允许在需要时对转储进行调整和暂停;&lt;/li&gt;&#xA;&lt;li&gt;不会获取表级锁，这可以防止影响源数据库上的写流量;&lt;/li&gt;&#xA;&lt;li&gt;支持任何类型的输出，因此，输出可以是流、数据存储甚或是 API;&lt;/li&gt;&#xA;&lt;li&gt;设计充分考虑了高可用性。因此，下游的消费者可以放心，只要源端发生变化，它们就可以收到变化事件。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;注意, 本文并非详细介绍 &lt;code&gt;DBLog&lt;/code&gt; 框架本身, 而是分析其框架背后的设计思路.&lt;/p&gt;&#xA;&lt;h2 id=&#34;算法流程&#34;&gt;算法流程&lt;/h2&gt;&#xA;&lt;h3 id=&#34;chunk-划分&#34;&gt;chunk 划分&lt;/h3&gt;&#xA;&lt;p&gt;对于源表数据, 全量数据使用分块读取, 基于 &lt;code&gt;primary key&lt;/code&gt; 顺序排序, 将全量数据划分为 N 个 chunk;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/DBLog-2.svg&#34; alt=&#34;DBLog-2&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;watermark&#34;&gt;watermark&lt;/h3&gt;&#xA;&lt;p&gt;基于 chunk 划分, 然后 chunk 数据全量写入下游之后, 再将源表的变更记录 &lt;code&gt;changelog&lt;/code&gt; 增量同步到下游, 整体思路就是这样, 但是划分 chunk 有个问题需要解决, 就是先同步到下游的数据不一定的最终的数据, 例如上图 chunk1 中的数据在同步到下游之后可能会删除, 那chunk1 的数据写到下游之后, 下游就会出现脏数据; 如何解决 chunk 和 &lt;code&gt;changelog&lt;/code&gt; 之间不会相互覆盖的问题?&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Dataflow Model 阅读笔记</title>
      <link>https://qiref.github.io/post/2023/05/16/the-dataflow-model-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 16 May 2023 15:26:10 +0800</pubDate>
      <guid>https://qiref.github.io/post/2023/05/16/the-dataflow-model-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;h2 id=&#34;dataflow-计算模型&#34;&gt;Dataflow 计算模型&lt;/h2&gt;&#xA;&lt;p&gt;Dataflow 的核心计算模型非常简单，它只有两个概念，一个叫做 ParDo，就是并行处理的意思；另一个叫做 GroupByKey，也就是按照 Key 进行分组。&lt;/p&gt;&#xA;&lt;h3 id=&#34;pardo&#34;&gt;ParDo&lt;/h3&gt;&#xA;&lt;p&gt;ParDo 用来进行通用的并行化处理。每个输入元素（这个元素本身有可能是一个有限的集合）都会使用一个 UDF 进行处理（在Dataflow中叫做DoFn），输出是0或多个输出元素。这个例子是把键的前缀进行展开，然后把值复制到展开后的键构成新的键值对并输出。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/dataflow-pardo.svg&#34; alt=&#34;dataflow-pardo&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;groupbykey&#34;&gt;GroupByKey&lt;/h3&gt;&#xA;&lt;p&gt;GroupByKey 用来按 Key 把元素重新分组。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://qiref.github.io/assets/img/dataflow-group-by-key.svg&#34; alt=&#34;dataflow-group-by-key&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;ParDo 操作因为是对每个输入的元素进行处理，因此很自然地就可以适用于无边界的数据。而 GroupByKey 操作，在把数据发送到下游进行汇总前，需要收集到指定的键对应的所有数据。如果输入源是无边界的，那么我们不知道何时才能收集到所有的数据。所以通常的解决方案是对数据使用窗口操作。&lt;/p&gt;&#xA;&lt;h2 id=&#34;窗口&#34;&gt;窗口&lt;/h2&gt;&#xA;&lt;h3 id=&#34;时间语义&#34;&gt;时间语义&lt;/h3&gt;&#xA;&lt;p&gt;窗口通常基于时间，时间对于窗口来说是必不可少的，在流式计算中，有 processing-time 和 event-time 两种时间语义，具体参考： &lt;a href=&#34;https://archieyao.github.io/posts/2022-02-25-flink-%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89/&#34;&gt;时间语义&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;窗口分类&#34;&gt;窗口分类&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;固定窗口（Fixed Window）固定区间（互不重叠）的窗口，可以基于时间，也可以基于数量；将事件分配到不同区间的窗口中，在通过窗口边界后，窗口内的所有事件会发送给计算函数进行计算；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;滑动窗口（Sliding Window）固定区间但可以重叠的窗口，需要指定窗口区间以及滑动步长，区间重叠意味着同一个事件会分配到不同窗口参与计算。 窗口区间决定何时触发计算，滑动步长决定何时创建一个新的窗口；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;会话窗口（Session Window）会话窗口通常基于用户的会话，通过定义会话的超时时间，将事件分割到不同的会话中； 例如，有个客服聊天系统，如果用户超过 30 分钟没有互动，则认为一次会话结束，当客户下次进入，就是一个新的会话了。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;窗口分配与合并&#34;&gt;窗口分配与合并&lt;/h3&gt;&#xA;&lt;p&gt;Dataflow 模型里，需要的不只是 GroupByKey，实际在统计数据的时候，往往需要的是 GroupByKeyAndWindow。统计一个不考虑任何时间窗口的数据，往往是没有意义的；&#xA;Dataflow 模型提出：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;从模型简化的角度上，把所有的窗口策略都当做非对齐窗口，而底层实现来负责把对齐窗口作为一个特例进行优化。&lt;/li&gt;&#xA;&lt;li&gt;窗口操作可以被分隔为两个互相相关的操作：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;set&amp;lt;Window&amp;gt; AssignWindows(T datum)&lt;/code&gt; 即窗口分配操作。这个操作把元素分配到 0 或多个窗口中去。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;set&amp;lt;window&amp;gt; MergeWindows(Set&amp;lt;Window&amp;gt; windows)&lt;/code&gt; 即窗口合并操作，这个操作在汇总时合并窗口。&#xA;而在实际的逻辑实现层面，Dataflow 最重要的两个函数，也就是 AssignWindows 函数和 MergeWindows 函数。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4 id=&#34;窗口分配&#34;&gt;窗口分配&lt;/h4&gt;&#xA;&lt;p&gt;每一个原始的事件，在业务处理函数之前，其实都是（key, value, event_time）这样一个三元组。而 AssignWindows 要做的，就是把这个三元组，根据我们的处理逻辑，变成（key, value, event_time, window）这样的四元组。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chandy-Lamport 算法笔记</title>
      <link>https://qiref.github.io/post/2023/05/08/chandy-lamport-%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Mon, 08 May 2023 22:38:42 +0800</pubDate>
      <guid>https://qiref.github.io/post/2023/05/08/chandy-lamport-%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;Global Snapshot（Global State）：全局快照，分布式系统在 Failure Recovery 的时候非常有用，也是广泛应用在分布式系统，更多是分布式计算系统中的一种容错处理理论基础。&lt;/p&gt;&#xA;&lt;p&gt;在 Chandy-Lamport 算法中，为了定义分布式系统的 Global Snapshot，先将分布式系统简化成有限个进程和进程之间的 channel 组成，也就是一个有向图 （GAG）：节点是进程，边是 channel。因为是分布式系统，也就是说，这些进程是运行在不同的物理机器上的。那么一个分布式系统的  Global Snapshot 就是有进程的状态和 channel 中的 message 组成，这个也是分布式快照算法需要记录的。因此，Chandy-Lamport 算法解决了分布式系统在 Failure Recovery 时，可以从  Global Snapshot 中恢复的问题；&lt;/p&gt;&#xA;&lt;h2 id=&#34;算法过程&#34;&gt;算法过程&lt;/h2&gt;&#xA;&lt;h3 id=&#34;前提条件及定义&#34;&gt;前提条件及定义&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;process（Pn）：分布式系统中的进程，用 P1，P2，P3 表示；&lt;/li&gt;&#xA;&lt;li&gt;channel：分布式系统中，Pn 与 Pm 通信的管道，C12 表示从 P1 到 P2 的 channel，反之，C32 表示从 P3 到 P2的 channel；&lt;/li&gt;&#xA;&lt;li&gt;message：分布式系统中，Pn 与 Pm 之间发送的业务消息；M23 表示从 P2 到 P3 的 message；&lt;/li&gt;&#xA;&lt;li&gt;marker：在 Chandy-Lamport 算法中，Pn 与 Pm 之间发送的标记消息，不同于业务的 message，marker 是由 Chandy-Lamport 算法定义，用于帮助实现快照算法；&lt;/li&gt;&#xA;&lt;li&gt;snapshot/state：都表示快照，同时包括进程本身的状态和 message；下文中统一全局快照叫 snapshot，process 本地快照叫 state；&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Chandy-Lamport 算法有一些前提条件：&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
